
val df = spark.read.schema("""symboling INT, normalized-losses INT,make STRING, fuel-type STRING, aspiration STRING,num-of-doors STRING, body-style STRING,drive-wheels STRING, engine-location STRING, wheel-base DOUBLE, length DOUBLE, width DOUBLE, height DOUBLE, curb-weight INT, engine-type STRING, num-of-cylinders STRING, engine-size INT, fuel-system STRING, bore DOUBLE, stroke DOUBLE,compressionratio DOUBLE, horsepower DOUBLE, peak-rpm DOUBLE, city-mpg INT, highway-mpg INT, price DOUBLE""").option("header",false).csv("Automobile_data.csv")



normalized-losses ?

num-of-doors

bore

stroke

horsepower

peak-rpm



price

df.filter("price = '?'").select($"normalized-losses",$"num-of-doors",$"bore",$"bore",$"stroke",$"horsepower",$"peak-rpm",$"price").show


df.filter("price = '?' or horsepower = '?' or `num-of-doors` ='?' or  `normalized-losses` = '?' or bore ='?' or stroke = '?' or `peak-rpm` = '?' ").select($"normalized-losses",$"num-of-doors",$"bore",$"stroke",$"horsepower",$"peak-rpm",$"price").show 

df.filter("price != '?' and horsepower != '?' and `num-of-doors` != '?' and   `normalized-losses` != '?' and bore !='?' and stroke != '?' and `peak-rpm` != '?' ").count

automobileData.select($"make",$"city-mpg").sort($"city-mpg".desc).limit(10).coalesce(1).write.mode("overwrite").option("header",true).csv("top_10_city_mpg.csv")

automobileData.select($"make").distinct.coalesce(1).write.mode("overwrite").option("header",true).csv("distinct_makers.csv")




val df = spark.read.csv("ashwin/Data/Automobile_data.csv")

val df = spark.read.schema("symboling INT, normalized_losses INT,make STRING, fuel_type STRING, aspiration STRING,num_of_doors STRING, body_style STRING,drive_wheels STRING, engine_location STRING, wheel_base DOUBLE, length DOUBLE, width DOUBLE, height DOUBLE, curb_weight INT, engine_type STRING, num_of_cylinders STRING, engine_size INT, fuel_system STRING, bore DOUBLE, stroke DOUBLE,compression_ratio DOUBLE, horsepower DOUBLE, peak_rpm DOUBLE, city_mpg INT, highway_mpg INT, price DOUBLE").option("header",true).csv("ashwin/Data/Automobile_data.csv")


df.filter("price = '?' or horsepower = '?' or `num_of_doors` ='?' or  `normalized_losses` = '?' or bore ='?' or stroke = '?' or `peak_rpm` = '?' ").select($"normalized_losses",$"num_of_doors",$"bore",$"stroke",$"horsepower",$"peak_rpm",$"price").show 


df.filter("price = '?' or horsepower = '?' or num_of_doors ='?' or  normalized_losses = '?' or bore ='?' or stroke = '?' or peak_rpm = '?' or price is null or horsepower is null or num_of_doors is null or  normalized_losses is null or bore is null or stroke is null or peak_rpm is null").select($"normalized_losses",$"num_of_doors",$"bore",$"stroke",$"horsepower",$"peak_rpm",$"price").show 


df.select("normalized_losses").filter("normalized_losses is not null").agg(avg("normalized_losses").alias("mean_normalized_losses")).show

--122


df.select("num_of_doors").filter("num_of_doors is not null").groupBy($"num_of_doors").agg(count(lit(1)).alias("mode_num_of_doors")).show
--four


df.select("horsepower").filter("horsepower is not null").agg(avg("horsepower").alias("mean_horsepower")).show

--104.25615763546799

df.select("bore").filter("bore is not null").agg(avg("bore").alias("mean_bore")).show

--3.3297512437810957

df.select("stroke").filter("stroke is not null").agg(avg("stroke").alias("mean_stroke")).show

--3.2554228855721337

df.select("peak_rpm").filter("peak_rpm is not null").agg(avg("peak_rpm").alias("peak_rpm")).show

--5125.369458128079

df.select("price").filter("price is not null").agg(avg("price").alias("mean_price")).show

--13207.129353233831

df.select($"normalized_losses",$"num_of_doors",$"bore",$"stroke",$"horsepower",$"peak_rpm",$"price").show



